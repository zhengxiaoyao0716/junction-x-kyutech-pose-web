# 基于骨骼的运动/训练场所危险动作识别

概述

在室内体育馆和训练场馆中，参与者可能会做出危险动作，例如攀爬、跨越围栏、跌倒和异常步态，如果未能及时发现，可能会导致受伤。本项目构建了一个基于骨骼的实时动作识别和预警系统，该系统从视频中提取人体关键点，对危险动作进行分类，并通过 API 和事件流发出警报。目标是通过低延迟和实际部署来改善安全管理。

问题设置和目标

应用场景：体育馆和训练场。
目标动作：攀爬、跨越围栏、跌倒、异常步态和长时间不活动（静态异常）。
核心目标：

输入：人体骨骼关键点序列；输出：每个人的动作类别。

实时推理：≥15 FPS，端到端延迟 ≤500 毫秒。

提供 API 服务和事件流，方便系统集成。
技术方法
2.1 姿态估计（关键点提取）

模型：RTMPose，用于快速、易于部署的二维关键点提取。

系统设计：

在场地进行本地实时推理；

Web/API 模式，用于调用本地推理或云端点（可配置）。

输出张量：N 个人 × T 帧 × K 个关键点 × 2 (x,y) 加上可见性/置信度。

默认为二维 (RTMPose)。三维是可选的未来工作。

注意：多人追踪和 ByteTrack 关联需要人物边界框。如有需要，请使用 RTMPose 的集成检测器或轻量级预检测器（例如 YOLOv8）。

2.2 骨架序列建模（动作识别）

主干：ST-GCN 和 ST-Transformer。

训练：

在 NTU RGB+D 120 上进行预训练/热启动（骨架模态）；

在小型场地特定数据上进行微调（迁移学习）。

融合策略：后期融合（例如，对每个类别的概率进行加权平均），以结合 ST-GCN 和 ST-Transformer。

输出：每个类别的概率和每个人的置信度。

2.3 时间后处理

时间平滑：滑动窗口加因果平滑 + TPA（时间概率聚合）以减少抖动。

ID 一致性：ByteTrack 用于跨帧的多人关联（保持稳定的人员 ID）。
2.4 API 和事件系统

服务：带有 WebSocket 的 FastAPI 用于流式输入/反馈；可选的 REST 端点用于批处理作业。

功能：

上传视频帧/流或预先提取的关键点 → 返回动作标签 + 置信度 + 警报标记。

事件总线（例如 Kafka/MQTT）将警报发布到仪表板，并存储关键帧快照以供人工审核。

数据与协议
3.1 数据源

用于预训练/基线 ​​ 的公共数据集：NTU RGB+D 120（主要数据集），可选 Kinetics-Skeleton 用于比较。

用于微调/评估的场地数据：在目标体育馆/训练场收集的视频（经同意并保护隐私）。

3.2 注释模式

类别：攀爬、穿越围栏、跌倒、异常步态、长时间不活动（静态异常）。

包含“正常”类别（例如站立/行走），以提高可辨别性和假阳性控制。

3.3 评估协议

跨对象：训练/测试由不同的参与者进行拆分，以评估跨人群的泛化能力。

跨场景：在不同场地、光照和服装下进行评估，以测试鲁棒性和领域转换。

在线实时评估：测量延迟、吞吐量（FPS）和运行时稳定性。
指标和目标（为了完整性）

危险类别的 Top-1 准确率/宏 F1。

延迟：端到端 ≤ 500 毫秒（摄像头 → 警报）。

吞吐量：目标硬件上每个视频流 ≥ 15 FPS。

稳定性：连续运行 ≥ 1 小时无崩溃；平滑后警报抖动低。

部署说明

硬件：多人场景优先使用 GPU；降低帧率后，CPU 回退。

隐私：仅在警报时存储关键帧；考虑人脸模糊处理；尽可能保留骨架而非原始视频。

安全性：API 的身份验证、速率限制和审计日志；可配置的警报阈值。
